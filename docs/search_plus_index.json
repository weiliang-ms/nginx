{"./":{"url":"./","title":"Introduction","keywords":"","body":"介绍 文档内容基于nginx-admins-handbook Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"-安装文档/":{"url":"-安装文档/","title":"-安装文档","keywords":"","body":"安装部署 下载最新release版本 release CentOS7 安装 rpm -ivh nginx-*-wl.el7.x86_64.rpm 关闭selinux setenforce 0 sed -i \"s#SELINUX=enforcing#SELINUX=disabled#g\" /etc/selinux/config 启动 systemctl daemon-reload systemctl enable nginx --now 查看状态 systemctl status nginx Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"02配置样例/01ssl配置样例.html":{"url":"02配置样例/01ssl配置样例.html","title":"01ssl配置样例","keywords":"","body":"配置ssl 适用于测试环境（自签证书） 生成证书 cd /etc/nginx/ssl /usr/sbin/generate-ssl.sh 配置ssl代理 生成配置文件，对配置文件内容变更,ssl部分不变。 cd /etc/nginx/conf/conf.d cp example/ssl.conf.example ssl.conf 调整后样例如下: server { listen 5443 ssl; ssl_protocols TLSv1.2; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_certificate /etc/ssl/nginx.crt; ssl_certificate_key /etc/ssl/nginx.key; server_name localhost; location / { proxy_pass http://127.0.0.1:8080 } } 查看监听是否生效 [root@localhost conf.d]# ss -aln|grep 5443 tcp LISTEN 0 128 *:5443 *:* 重载 systemctl reload nginx 启动8080监听 python -m SimpleHTTPServer 8080 防火墙开放5443端口 CentOS6 iptables -I INPUT -p tcp -m state --state NEW -m tcp --dport 5443 -j ACCEPT /etc/rc.d/init.d/iptables save service iptables restart CentOS7 firewall-cmd --zone=public --add-port=5443/tcp --permanent firewall-cmd --reload 浏览器访问nginx宿主机的5443端口验证ssl Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"03配置调优/01worker数量调优.html":{"url":"03配置调优/01worker数量调优.html","title":"01worker数量调优","keywords":"","body":"worker调优 原文地址 worker_processes是nginx的核心指令。 该指令用于声明：nginx启动时，将会启动多少个worker进程，当nginx运行在cpu密集型的宿主机上很有用。 最简单的方式就是配置为: auto。当然也可以根据高并发情况下的最大吞吐量调整此值。 从合理利用计算资源的角度来看，应该根据可用内核数、磁盘、网络子系统、服务器负载等将该值更改为最佳值。 应该配置多少个worker进程？ 首先，对nginx进行压力测试，测试当配置一个worker进程时，负载情况。 然后，依次增加worker数量，继续观测负载情况，直到服务器资源达到真正饱和的程度。 此时，worker数量便有了对应的值。 尽可能为系统预留一部分cpu计算资源 对于高负载代理服务器(也包括独立服务器)，更合理的值应为：worker num = ALL_CORES - 1 (或更多) 因为如果你在同一台服务器上运行NGINX和其他关键服务，通过预留一部分CPU核给其他关键服务或系统服务， 避免nginx高负载运行情况下对系统/其他关系服务产生严重影响。 经验值 当nginx在处理请求时，很大一部分时间用于处理I/O，那么此时需要增加worker进程数量。 官方建议 nginx官方文档说明如下: 当你不知道该如何设置这个参数时，将其设置为可用CPU核的数量将是一个很好的选择。 即每个CPU内核运行一个worker进程，这种方式能最有效地使用硬件资源。 # 推荐方式: worker_processes auto; # 可选方式: # VCPU = 4 ，worker_processes = VCPU - 1 # VCPU -> grep \"processor\" /proc/cpuinfo | wc -l worker_processes 3; Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"03配置调优/02使用HTTP2.html":{"url":"03配置调优/02使用HTTP2.html","title":"02使用HTTP2","keywords":"","body":"使用HTTP2.0 HTTP/2将使我们的应用程序更快、更简单、更健壮: HTTP/2的主要目标是通过启用完整的请求和响应多路复用来减少延迟， 通过HTTP报头字段的有效压缩来最小化协议开销， 并增加对请求优先级和服务器推送的支持。 HTTP/2也有一个非常大的旧的和不安全的密码黑名单。 http2指令配置端口接受HTTP/2连接 HTTP/2向后兼容HTTP/1.1，如果客户端不支持HTTP/2，那么nginx与客户端间通信将采用HTTP/1协议 配置样例 ```nginx configuration server { ... listen 8081 http2; ... } `HTTP/2`在一个单一的`TCP`连接复用多个`http`请求，通常情况当服务端使用`HTTP/2`时，客户端将建立单个`TCP`连接与服务端通信。 > 开启`HTTP/2`的同时应开启`ssl` 因为绝大多数情况下，浏览器不支持没有加密的`HTTP/2`(尽管`h2`规范中允许使用`HTTP/2`在一个不安全的`http://`, 即没有加密证书的情况。但是浏览器没有实现(大多数浏览器并不打算))。 注意：通过`TLS`接受`HTTP/2`连接需要`应用层协议协商`(ALPN) `TLS`扩展支持。 ```nginx configuration server { listen 10.240.20.2:443 ssl http2; ... Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"03配置调优/03SSL加固.html":{"url":"03配置调优/03SSL加固.html","title":"03SSL加固","keywords":"","body":"SSL会话缓存 默认情况下，内置会话缓存功能是不合理的，因为该缓存只能被一个worker进程使用，并且可能导致内存碎片化。 使用ssl_session_cache指令处理会话缓存可以降低NGINX服务器的CPU开销。 从客户端角度来看，通过对ssl会话缓存可以提高系统性能。其原理主要是：消除了每次发出请求时都需要进行新的(且耗时的)SSL握手的需要。 ssl_session_cache值该怎么设？ 当启用ssl_session_cache时，通过SSL保持的连接，性能会大大提高。 建议ssl_session_cache值设为10M(1MB共享缓存可以容纳大约4000个会话)。 共享的缓存在所有worker进程之间共享(同名的缓存可以在多个虚拟服务器中使用，但不跨主机因为基于宿主机内存)。 ssl_session_timeout参数设置 对于TLSv1.2，会话的缓存时间不应超过24小时(这是最大时间)。 通常，TLS会话不应该被恢复，除非客户端和服务器都同意，并且如果任何一方怀疑会话可能已被泄露，或者证书可能已过期或已被吊销，则应该强制执行完全握手。 但是一段时间以前，我发现ssl_session_timeout设置较短的时间(例如15分钟)可以防止被广告商滥用，如谷歌和Facebook，针对这这种情况是有意义的。 建议值设置为 nginx configuration ssl_session_timeout 4h; ssl_buffer_size参数设置 开启OCSP Stapling Enable OCSP Stapling 与OCSP不同，在OCSP Stapling机制中，用户的浏览器不会直接访问证书的颁发者进行证书校验，而是由应用服务器定期访问颁发者进行证书校验。 OCSP Stapling扩展配置是为了更好的性能(旨在减少OCSP验证的成本;提高浏览器与应用服务器的通信性能， 并允许在访问应用程序时检索有关证书有效性的信息)，用户隐私仍然得到维护。OCSP Stapling只是一种优化，即使他不起作用，也不会中断程序。 在没有实现OCSP Stapling扩展的情况下使用OCSP，会增加丢失用户隐私的风险， 以及由于无法验证证书的有效性而对应用程序的可用性造成负面影响的风险。 OCSP Stapling在TLS证书状态请求(RFC 6066 -证书状态请求)扩展(Stapling)中定义了OCSP响应。 在这种情况下，服务器发送OCSP响应作为TLS扩展的一部分，因此客户端不需要在OCSP URL上检查它(为客户端节省了撤销检查时间)。 nginx提供了几个需要记住的选项。 例如:它从ssl_trusted_certificate所指向的证书文件生成列表(这些证书的列表将不会发送到客户端)。 您需要发送这个列表或关闭ssl_verify_client。 当ssl_certificate语句已经提供了完整的证书链(只有中级证书，没有根CA，而且必须不包括站点证书)时， 此步骤是可选的。如果只使用证书(而不是CA的部分)，则需要ssl_trusted_certificate。 Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"03配置调优/04使用server_name代替if指令判断domain.html":{"url":"03配置调优/04使用server_name代替if指令判断domain.html","title":"04使用server_name代替if指令判断domain","keywords":"","body":"不要使用if指令判断domain 原文地址 更多nginx文档 更多linux相关文档 原理分析 当NGINX接收到一个请求时，如果你配置了if指令用于检查每个请求的Host头， 不管请求的子域是什么，无论是www.example.com，还是example.com，都将执行该if指令进行判断。 相反，使用两个server指令，如下面的例子所示。这种方法降低了NGINX处理需求。 样例 错误的实现方式: ```nginx configuration server { server_name example.com www.example.com; if ($host = www.example.com) { return 301 https://example.com$request_uri; } server_name example.com; ... } - 正确的实现方式: ```nginx configuration server { listen 192.168.252.10:80; server_name www.example.com; return 301 $scheme://example.com$request_uri; # If you force your web traffic to use HTTPS: # return 301 https://example.com$request_uri; ... } server { listen 192.168.252.10:80; server_name example.com; ... } 其他场景 不光$server_name指令，当判断$scheme值时，也应该用多个server代替if判断如。 在某些情况下(但并非总是如此)，添加一个额外的块指令比使用if更好。 官方建议： 在location上下文中使用if会存在一些问题，尽量避免。 Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"03配置调优/05使用$request_uri代替正则.html":{"url":"03配置调优/05使用$request_uri代替正则.html","title":"05使用$request_uri代替正则","keywords":"","body":"使用$request_uri代替正则 原文地址 更多nginx文档 更多linux相关文档 原理分析 使用内置的$request_uri，我们可以有效地避免任何捕获或匹配操作(cpu计算)，通常正则批量会增加CPU开销，从而降低系统整体性能 当规则为变换Host时（URI不变），直接使用$request_uri拼接新host更加高效。 $request_uri的值总是从客户端接收到的原始URI(带参数的完整原始请求URI)，与$URI指令相比不受任何规范化的约束 如果你需要匹配URI和它的查询字符串，可以在map指令中使用$request_uri 如果不加考虑地使用$request_uri会导致许多奇怪的行为。例如，在错误的地方使用$request_uri可能会导致URL编码字符变成双编码。 所以大多数时候你应使用$uri，因为它是标准化的。 样例 不建议实现方式 ```nginx configuration 1) rewrite ^/(.*)$ https://example.com/$1 permanent; 2) rewrite ^ https://example.com$request_uri permanent; - 建议实现方式 ```nginx configuration return 301 https://example.com$request_uri; Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"03配置调优/06使用try_files指令来确保文件存在.html":{"url":"03配置调优/06使用try_files指令来确保文件存在.html","title":"06使用try_files指令来确保文件存在","keywords":"","body":"使用try_files指令来确保文件存在 原文地址 更多nginx文档 更多linux相关文档 解释说明 try_files绝对是一个非常有用的指令：你可以使用try_files指令来检查文件是否按照指定的顺序存在。 应该使用try_files代替if指令，因为if指令的效率非常低，因为它对每个请求都进行判断 使用try_files的优点是：只需一个命令就可以立即切换行为，代码也更易读。 try_files指令允许你： 检查文件是否存在于预定义列表中 检查指定目录中是否存在该文件 如果没有找到任何文件，则使用内部重定向 使用样例 不建议实现方式 ```nginx configuration server { ... root /var/www/example.com; location /images { if (-f $request_filename) { expires 30d; break; } ... } - 建议实现方式 ```nginx configuration server { ... root /var/www/example.com; location /images { try_files $uri =404; ... } Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"03配置调优/07使用return代替rewrite做重定向.html":{"url":"03配置调优/07使用return代替rewrite做重定向.html","title":"07使用return代替rewrite做重定向","keywords":"","body":"使用return代替rewrite做重定向 原文地址 更多nginx文档 更多linux相关文档 解释说明 NGINX中重写url的能力是一个非常强大和重要的特性，从技术角度讲return与rewrite均能实现。 但使用return相对rewrite更简单和更快，因为计算RegEx会产生额外的系统开销。 Return指令可以立即停止处理请求(它直接停止执行)并将指定的代码返回给客户端，省略了正则计算的流程。 如果你需要用regex验证URL或者需要获取原始URL中的元素(显然不在相应的NGINX变量中)，那么你应该使用rewrite 使用样例 不建议实现方式 ```nginx configuration server { ... location / { try_files $uri $uri/ =404; rewrite ^/(.*)$ https://example.com/$1 permanent; } ... } - 建议实现方式 ```nginx configuration server { ... location / { try_files $uri $uri/ =404; return 301 https://example.com$request_uri; } ... } Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"03配置调优/08启用PCRE-JIT以加速正则表达式的处理.html":{"url":"03配置调优/08启用PCRE-JIT以加速正则表达式的处理.html","title":"08启用PCRE-JIT以加速正则表达式的处理","keywords":"","body":"启用PCRE JIT以加速正则表达式的处理 原文地址 更多nginx文档 更多linux相关文档 使用pcre_jit的优势 正则检查规则可能非常耗时，尤其是复杂的正则表达式(regex)条件，允许对正则表达式使用JIT可以加快处理速度。 通过使用PCRE库编译NGINX，可以用location块执行复杂的操作，并使用强大的rewrite指令 PCRE JIT规则匹配引擎可以显著提高正则表达式的处理速度，带有pcre_jit的NGINX比没有它的NGINX快很多（处理正则表达式）。 这个选项可以提高性能。 使用pcre_jit的劣势 在某些情况下，开启pcre_jit可能有负面影响，具体参考PCRE性能优化 启用方式 pcre8.20+ nginx编译时添加参数: --with-pcre=path_to_pcre8.20+ --with-pcre-jit 使用方式 nginx configuration http { ... pcre_jit on; ... } Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"03配置调优/09upstream开启keepalive.html":{"url":"03配置调优/09upstream开启keepalive.html","title":"09upstream开启keepalive","keywords":"","body":"upstream开启keepalive 原文地址 更多nginx文档 更多linux相关文档 解释说明 配置keepalive的主要意图：解决在高延迟网络上建立TCP连接的延迟问题。 当nginx与上游服务器之间需要持续保持一定数量的连接时，keepalive很有用。 开启Keep-Alive连接对性能有很大的影响：减少了打开和关闭连接所需的CPU和网络开销。 通过在nginx中启用HTTP keepalive，降低了nginx连接上游服务器的延迟，从而提高了性能，并减少了nginx耗尽临时端口的可能性。 nginx将重用现有的TCP连接,而不创建新的TCP, 这可以极大地减少繁忙服务器上TIME_WAIT TCP连接中的套接字数量(减少操作系统建立新连接的工作，减少网络上的数据包) 注意： 仅在HTTP/1.1时支持Keep-Alive连接。 配置样例 ```nginx configuration Upstream context: upstream backend { Sets the maximum number of idle keepalive connections to upstream servers that are preserved in the cache of each worker process. keepalive 16; } Server/location contexts: server { ... location / { # By default only talks HTTP/1 to the upstream, # keepalive is only enabled in HTTP/1.1: proxy_http_version 1.1; # Remove the Connection header if the client sends it, # it could be \"close\" to close a keepalive connection: proxy_set_header Connection \"\"; ... } } ``` Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"03配置调优/10尽可能精准配置location.html":{"url":"03配置调优/10尽可能精准配置location.html","title":"10尽可能精准配置location","keywords":"","body":"location尽可能的精确 原文地址 更多nginx文档 更多linux相关文档 解释说明 精确的location匹配通常被用来加快选择过程，匹配通过后立即结束算法的执行。 使用=修饰符可以定义URI和location的精确匹配。它的处理速度非常快，可以节省大量的CPU开销。 ```nginx configuration location = / { ... } Matches the query /v9 only and stops searching: location = /v9 { ... } ... 如果找到精确匹配，则搜索终止。 例如，存在`/`请求，并且请求的频率比较高，则可以定义`location = /`加快这些请求的处理速度。 ### 关于nginx location匹配顺序 **例子来源以下地址** [https://github.com/trimstray/nginx-admins-handbook#introduction](https://github.com/trimstray/nginx-admins-handbook#introduction) > 假设配置如下 ```nginx configuration server { listen 80; server_name xyz.com www.xyz.com; location ~ ^/(media|static)/ { root /var/www/xyz.com/static; expires 10d; } location ~* ^/(media2|static2) { root /var/www/xyz.com/static2; expires 20d; } location /static3 { root /var/www/xyz.com/static3; } location ^~ /static4 { root /var/www/xyz.com/static4; } location = /api { proxy_pass http://127.0.0.1:8080; } location / { proxy_pass http://127.0.0.1:8080; } location /backend { proxy_pass http://127.0.0.1:8080; } location ~ logo.xcf$ { root /var/www/logo; expires 48h; } location ~* .(png|ico|gif|xcf)$ { root /var/www/img; expires 24h; } location ~ logo.ico$ { root /var/www/logo; expires 96h; } location ~ logo.jpg$ { root /var/www/logo; expires 48h; } } 匹配规则如下 请求URL 相匹配的location 最终匹配 / 1) prefix match for / / /css 1) prefix match for / / /api 1) exact match for /api /api /api/ 1) prefix match for / / /backend 1) prefix match for /2) prefix match for /backend /backend /static 1) prefix match for / / /static/header.png 1) prefix match for /2) case sensitive regex match for ^/(media\\ static)/ ^/(media\\ static)/ /static/logo.jpg 1) prefix match for /2) case sensitive regex match for ^/(media\\ static)/ ^/(media\\ static)/ /media2 1) prefix match for /2) case insensitive regex match for ^/(media2\\ static2) ^/(media2\\ static2) /media2/ 1) prefix match for /2) case insensitive regex match for ^/(media2\\ static2) ^/(media2\\ static2) /static2/logo.jpg 1) prefix match for /2) case insensitive regex match for ^/(media2\\ static2) ^/(media2\\ static2) /static2/logo.png 1) prefix match for /2) case insensitive regex match for ^/(media2\\ static2) ^/(media2\\ static2) /static3/logo.jpg 1) prefix match for /static32) prefix match for /3) case sensitive regex match for logo.jpg$ logo.jpg$ /static3/logo.png 1) prefix match for /static32) prefix match for /3) case insensitive regex match for .(png\\ ico\\ gif\\ xcf)$ .(png\\ ico\\ gif\\ xcf)$ /static4/logo.jpg 1) priority prefix match for /static42) prefix match for / /static4 /static4/logo.png 1) priority prefix match for /static42) prefix match for / /static4 /static5/logo.jpg 1) prefix match for /2) case sensitive regex match for logo.jpg$ logo.jpg$ /static5/logo.png 1) prefix match for /2) case insensitive regex match for .(png\\ ico\\ gif\\ xcf)$ .(png\\ ico\\ gif\\ xcf)$ /static5/logo.xcf 1) prefix match for /2) case sensitive regex match for logo.xcf$ logo.xcf$ /static5/logo.ico 1) prefix match for /2) case insensitive regex match for .(png\\ ico\\ gif\\ xcf)$ .(png\\ ico\\ gif\\ xcf)$ 匹配顺序说明 nginx根据uri进行最优匹配： 基于前缀的nginx location匹配(没有正则表达式): 每个location都将根据请求URI进行检查 nginx搜索精确的匹配: 如果=修饰符与请求URI完全匹配，则立即选择此特定位置块 如果没有找到精确的位置块(即没有相应的=修饰符)，nginx将继续使用非精确的前缀。它从这个URI的最长匹配前缀位置开始，方法如下: 如果最长匹配前缀location有^~修饰符，nginx将立即停止搜索并选择该location 假设最长匹配前缀location不使用^~修饰符，匹配将被临时存储，并继续执行 一旦选择并存储了最长匹配前缀location，nginx就会继续计算区分大小写和不敏感的正则表达式location。 第一个匹配URI的正则表达式location将立即被选中来处理请求 如果没有找到匹配请求URI的正则表达式location，则选择先前存储的前缀location来服务请求 最长匹配解释说明： 请求为/a/b/c/d时，location A与location B中location B为最长匹配 location A nginx configuration location /a { ... } location B nginx configuration location /a/b/c { ... } Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"03配置调优/11开启limit_conn限制下载速度.html":{"url":"03配置调优/11开启limit_conn限制下载速度.html","title":"11开启limit_conn限制下载速度","keywords":"","body":"开启limit_conn限制下载速度 原文地址 更多nginx文档 更多linux相关文档 nginx提供了两个指令限制下载速度： limit_rate_after: 设置limit_rate指令生效前(未限速前)可传输的数据量 limit_rate: 允许您限制单个客户端连接的传输速率(超过limit_rate_after) 以上两个指令限制了nginx每次连接的下载速度，所以，如果一个用户打开x个视频文件，它将能够下载x *他连接到视频文件的个数。 使用样例 ```nginx configuration Create limit connection zone: limit_conn_zone $binary_remote_addr zone=conn_for_remote_addr:1m; Add rules to limiting the download speed: limit_rate_after 1m; # run at maximum speed for the first 1 megabyte limit_rate 250k; # and set rate limit after 1 megabyte Enable queue: location /videos { Max amount of data by one client: 10 megabytes (limit_rate_after * 10) limit_conn conn_for_remote_addr 10; ... } ``` Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"04安全加固/01安装最新版nginx.html":{"url":"04安全加固/01安装最新版nginx.html","title":"01安装最新版nginx","keywords":"","body":"使用最新版的nginx 使用最新版的nginx，nginx本身向后兼容。 Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"04安全加固/02使用非特权用户运行nginx.html":{"url":"04安全加固/02使用非特权用户运行nginx.html","title":"02使用非特权用户运行nginx","keywords":"","body":"使用非特权用户运行nginx 原文地址 更多nginx文档 更多linux相关文档 linux下一个很重要的通用原则: 程序只应拥有完成其工作所需的最小权限。这样，如果程序坏了，它对系统的损害是有限的。 仅仅通过更改进程所有者名称，在安全性方面并没有真正的区别。 而在安全方面，最小特权原则规定：进程实体在给定系统中实现其目标所必需的权限之外，不应该被授予更多的权限。这样，只有master进程作为root进程运行。 [root@localhost ~]# ps -ef|grep nginx root 1049 1 0 00:02 ? 00:00:00 nginx: master process /usr/sbin/nginx nginx 1051 1049 0 00:02 ? 00:00:00 nginx: worker process nginx 1052 1049 0 00:02 ? 00:00:00 nginx: cache manager process nginx 1053 1049 0 00:02 ? 00:00:00 nginx: cache loader process root 1317 1297 0 00:03 pts/0 00:00:00 grep --color=auto nginx 如果您使用这个仓库:nginx 的安装包进行安装，关于最小权限的配置已配置完毕： master进程运行user: root worker进程运行user: nginx 目录权限 /var/log/nginx: 日志目录(nginx:nginx) /var/cache/nginx: 缓存目录(nginx:nginx) /var/dump/nginx: dump目录(nginx:nginx) /etc/nginx: 配置目录(nginx:nginx) /usr/share/nginx: 静态文件目录(nginx:nginx) Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"04安全加固/03保护敏感资源.html":{"url":"04安全加固/03保护敏感资源.html","title":"03保护敏感资源","keywords":"","body":"保护敏感资源 原文地址 更多nginx文档 更多linux相关文档 隐藏的目录和文件永远不应该被web访问-有时关键数据会在应用程序部署期间发布。 如果你使用的是版本控制系统，发布程序时应该明确地禁止对关键隐藏目录/文件的访问(通过向攻击者提供更少的信息)，比如.git或.svn， 以防止暴露应用程序的源代码。 使用方式 server块添加include /etc/nginx/conf/conf.d/deny.location;配置 ```nginx configuration server { listen 8088; include /etc/nginx/conf/conf.d/deny.location; location / { return 200; } } `deny.location`内容如下： ```nginx configuration location ~* ^.*(\\.(?:git|svn|hg|bak|bckp|save|old|orig|original|test|conf|cfg|dist|in[ci]|log|sql|mdb|sw[op]|htaccess|php#|php~|php_bak|aspx?|tpl|sh|bash|bin|exe|dll|jsp|out|cache|))$ { # Use also rate limiting: # in server context: limit_req_zone $binary_remote_addr zone=per_ip_5r_s:5m rate=5r/s; limit_req zone=per_ip_5r_s; deny all; access_log /var/log/nginx/restricted-files-access.log main; access_log /var/log/nginx/restricted-files-error.log main; } 测试用例: [root@localhost conf.d]# curl 127.0.0.1:8088/.git -I HTTP/1.1 403 Forbidden Date: Sat, 16 Oct 2021 04:31:03 GMT Content-Type: text/html; charset=utf-8 Content-Length: 146 Connection: keep-alive Server: Unknown [root@localhost conf.d]# curl 127.0.0.1:8088/.sh -I HTTP/1.1 403 Forbidden Date: Sat, 16 Oct 2021 04:31:38 GMT Content-Type: text/html; charset=utf-8 Content-Length: 146 Connection: keep-alive Server: Unknown Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"04安全加固/04隐藏nginx版本信息.html":{"url":"04安全加固/04隐藏nginx版本信息.html","title":"04隐藏nginx版本信息","keywords":"","body":"隐藏版本信息 Hide Nginx version number 更多nginx文档 更多linux相关文档 隐藏版本信息(已内置) ```nginx configuration server_tokens off; > 修改`server`信息(已内置) ```nginx configuration more_set_headers \"Server: Unknown\"; 错误页 TODO Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"04安全加固/05配置ACL规则.html":{"url":"04安全加固/05配置ACL规则.html","title":"05配置ACL规则","keywords":"","body":"Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"04安全加固/06隐藏上游代理header头信息.html":{"url":"04安全加固/06隐藏上游代理header头信息.html","title":"06隐藏上游代理header头信息","keywords":"","body":"隐藏上游代理报头 Hide upstream proxy headers 更多nginx文档 更多linux相关文档 当nginx被用来反向代理上游服务器(比如一个PHP-fpm实例)时， 隐藏在上游响应中发送的某些报头(比如PHP运行的版本)是有益的。 可以使用proxy_hide_header(或Lua模块)来隐藏/删除上游服务器返回到你的nginx反向代理(并最终返回到客户端)的头文件。 使用方式 代理http服务的location块添加include /etc/nginx/conf/conf.d/hide-headers.rule;配置 ```nginx configuration upstream ddd-server { server 11.11.11.11:80; server 11.11.11.12:80; } server { listen 8081; location /ddd { include /etc/nginx/conf/conf.d/hide-headers.rule; proxy_pass http://ddd-server; } } `/etc/nginx/conf/conf.d/hide-headers.rule`: ```nginx configuration proxy_hide_header X-Application-Context; proxy_hide_header Access-Control-Allow-Origin; proxy_hide_header X-Powered-By; proxy_hide_header X-AspNetMvc-Version; proxy_hide_header X-Drupal-Cache; proxy_hide_header X-Powered-By; proxy_hide_header Server; proxy_hide_header X-AspNet-Version; proxy_hide_header X-Drupal-Dynamic-Cache; proxy_hide_header X-Generator; proxy_hide_header X-Runtime; proxy_hide_header X-Rack-Cache; Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"04安全加固/07禁用不安全方法.html":{"url":"04安全加固/07禁用不安全方法.html","title":"07禁用不安全方法","keywords":"","body":"禁用不安全的HTTP方法 Reject unsafe HTTP methods 更多nginx文档 更多linux相关文档 一般web服务支持GET、HEAD和POST方法来检索静态和动态内容。 公开的web服务不应该支持其他HTTP(例如OPTIONS, TRACE)方法，因为它们增加了攻击面。 通常生产环境下应该禁用这些方法（如果您确实不需要该方法） TRACE方法安全隐患: 开启TRACE方法可能导致Cross-Site Tracing（允许跨站点跟踪）攻击，该攻击可以捕获另一个应用程序用户的会话ID。 并且，该方法还可以用来尝试识别有关应用程序操作的环境的附加信息(例如，应用程序路径上是否存在缓存服务器)。 OPTIONS方法安全隐患: 开启OPTIONS方法并不会产生直接威胁，但攻击者可以从OPTIONS方法响应获取额外信息的来源，进而被攻击者利用已知漏洞。 HEAD方法安全隐患: 开启HEAD方法同样存在风险：尽管它并不被认为是危险的， 但它可以被用来通过模仿GET请求来攻击web应用程序。 其次，使用HEAD可以通过限制服务器发送的数据量来加快攻击进程。 如果授权机制基于GET和POST，那么HEAD方法可以允许绕过这些保护。 我认为，HEAD请求通常被代理或CDN用来有效地确定一个页面是否已经改变，而不需要下载整个页面(它对于检索写在响应头中的元信息很有用)。 更重要的是，如果禁用它，只会增加吞吐量成本。 如何通过nginx拦截HTTP方法? 在配置拦截任何一种方法之前，需要了解401、403和405 HTTP这几个响应代码之间差异，建议使用405状态码： 1: 405 Method Not Allowe表示服务端不允许使用当前类型HTTP方法请求当前uri 2: 401 Unauthorized表示当前用户未经认证授权，无权访问当前uri 3: 403 Forbidden表示当前用户未通过鉴权，无权访问当前uri 在我看来，如果uri不能用给定的HTTP方法处理请求，它应该发送一个Allow头来列出允许的HTTP方法。 为此，您可以使用add_header添加响应信息。 推荐配置 ```nginx configuration server { ... # If we are in server context, it’s good to use construction like this: add_header Allow \"GET, HEAD, POST\" always; if ($request_method !~ ^(GET|HEAD|POST)$) { # You can also use 'add_header' inside 'if' context: # add_header Allow \"GET, HEAD, POST\" always; return 405; } ... } ``` Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"04安全加固/08避免敏感数据的缓存.html":{"url":"04安全加固/08避免敏感数据的缓存.html","title":"08避免敏感数据的缓存","keywords":"","body":"避免敏感数据的缓存 Prevent caching of sensitive data 更多nginx文档 更多linux相关文档 尽管这个策略应该由应用本身实现，但是，很多时候还是需要反向代理服务进行处理。 不要缓存或持久化敏感数据 由于浏览器对缓存HTTPS内容有不同的默认行为，包含敏感信息的页面应该包含Cache-Control头，以确保内容不被缓存。 实现方式 在响应中添加防缓存头，例如: Cache-Control: no-cache, no-store和Expires: 0 为了兼容多种浏览器实现，建议响应头配置如下:Cache-Control: no-cache, no-store, private, must-revalidate, max-age=0, no-transform Pragma: no-cache Expires: 0 nginx配置样例 基于location上下文 ```nginx configuration location /api { expires 0; add_header Pragma \"no-cache\"; add_header Cache-Control \"no-cache, no-store, private, must-revalidate, max-age=0, no-transform\"; } ``` Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"04安全加固/09限制并发连接.html":{"url":"04安全加固/09限制并发连接.html","title":"09限制并发连接","keywords":"","body":"限制并发连接 Limit concurrent connections 更多nginx文档 更多linux相关文档 nginx提供了最为基本的方式防御DoS之类的拒绝服务攻击。默认情况下，用户可以拥有的活动连接数没有限制。 nginx支持全局(在nginx http上下文中)切断冗余/不必要的连接，但如果配置全局的限制，可能会对一些server监听产生影响。 当然nginx也支持在每个location下文中设置它，例如，为搜索页面，在线用户显示，成员列表等location设置它。 ```nginx configuration http { limit_conn_zone $binary_remote_addr zone=slimit:10m; Set globally: limit_conn slimit 10; ... server { # Or in the server context: limit_conn slimit 10; ... } } ``` Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"04安全加固/10防御缓冲区溢出攻击.html":{"url":"04安全加固/10防御缓冲区溢出攻击.html","title":"10防御缓冲区溢出攻击","keywords":"","body":"防御缓冲区溢出攻击 Control Buffer Overflow attacks 更多nginx文档 更多linux相关文档 缓冲区溢出攻击是通过将数据写入缓冲区并超过缓冲区的边界并覆盖进程的内存片段来实现的。 为了防止在nginx中出现这种情况，我们可以为所有客户端设置缓冲区大小限制。 如果nginx使用了整个服务器内存，那么大量的POST请求可以有效地导致DoS攻击。 允许将大文件上传到服务器可以使攻击者更容易利用系统资源并成功执行拒绝服务。 相应的值取决于服务器内存以及通信量。很久以前我发现了一个有趣的公式: MAX_MEMORY = client_body_buffer_size x CONCURRENT_TRAFFIC - OS_RAM - FS_CACHE 在我看来，使用较小的client_body_buffer_size(略大于10k，但不是那么多)肯定更好， 因为更大的缓冲区可以减轻DoS攻击向量，因为您将为它分配更多的内存。 提示: 如果请求体大于client_body_buffer_size，它将被写入磁盘，在内存中不可用，因此没有$request_body。 此外，将client_body_buffer_size设置过高可能会影响日志文件的大小(如果您记录$request_body)。 配置样例 nginx configuration client_body_buffer_size 128k; # default: 8k (32-bit) | 16k (64-bit) client_header_buffer_size 512k; # default: 1k client_max_body_size 10m; # default: 1m large_client_header_buffers 4 512k; # default: 4 8k Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"04安全加固/11缓解HTTP慢速DoS攻击.html":{"url":"04安全加固/11缓解HTTP慢速DoS攻击.html","title":"11缓解HTTP慢速DoS攻击","keywords":"","body":"缓解HTTP慢速DoS攻击 Mitigating Slow HTTP DoS attacks 更多nginx文档 更多linux相关文档 您可以关闭不太频繁写入数据的连接 ，过长的keepalive时间将降低服务器接受新连接的能力。 在我看来，2-3秒的keepalive_timeout对于大多数人来说已经足够解析HTML/CSS和检索所需的图像、图标， 设置过高keepalive_timeout将导致资源(主要是内存)的浪费，因为即使没有流量，连接也将保持打开状态，这对系统性能可能产生明显影响。 并且send_timeout最好设置的小些，这样一来web服务器将迅速关闭连接，释放资源，供新连接使用，从而提供系统吞吐。 当然超时配置还需根据实际情况进行配置，部分请求可能需要较长的时间接收响应（这部分请求最好在location上下文单独配置超时时间）。 配置样例(参考值) nginx configuration client_body_timeout 10s; # default: 60s client_header_timeout 10s; # default: 60s keepalive_timeout 5s 5s; # default: 75s send_timeout 10s; # default: 60s Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"05反向代理/01使用兼容后端服务的paas指令.html":{"url":"05反向代理/01使用兼容后端服务的paas指令.html","title":"01使用兼容后端服务的paas指令","keywords":"","body":"使用兼容后端服务的paas指令 原文地址 更多nginx文档 更多linux相关文档 根据上游服务选取合适的proxy_*指令 http: 使用proxy_pass uWSGI: 使用uwsgi_pass FastCGI: 使用fastcgi_pass 举例说明: uwsgi_pass指令将使用uwsgi协议，proxy_pass使用普通的HTTP协议与uWSGI服务通信。 uWSGI文档称uWSGI协议更好，更快，可以受益于所有的uWSGI特性。 比如：你可以向uWSGI服务端发送信息，说明你发送数据的类型，以及应该调用什么uWSGI插件来生成响应。 而使用proxy_pass将不能使用该特性。 配置样例: ```nginx configuration server { location /app/ { # backend layer: OpenResty as a front for app proxy_pass http://192.168.154.102:80; } location /app/v3 { # backend layer: uWSGI Python app uwsgi_pass 192.168.154.102:8080; } location /app/v4 { # backend layer: php-fpm app fastcgi_pass 192.168.154.102:8081; } ... } ``` Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"05反向代理/02正确使用proxy_pass后面的斜杠.html":{"url":"05反向代理/02正确使用proxy_pass后面的斜杠.html","title":"02正确使用proxy_pass后面的斜杠","keywords":"","body":"正确使用proxy_pass后面的斜杠 原文地址 更多nginx文档 更多linux相关文档 某些场景下，由于nginx反向代理配置调整了uri，你可能会得到一些奇怪的url。 TODO Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"05反向代理/03只使用$Host变量设置和传递主机头信息.html":{"url":"05反向代理/03只使用$Host变量设置和传递主机头信息.html","title":"03只使用$Host变量设置和传递主机头信息","keywords":"","body":"TODO Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"05反向代理/04proxy_pass中使用$request_uri代替$uri.html":{"url":"05反向代理/04proxy_pass中使用$request_uri代替$uri.html","title":"04proxy_pass中使用$request_uri代替$uri","keywords":"","body":"proxy_pass中使用$request_uri代替$uri 原文地址 更多nginx文档 更多linux相关文档 传递原生请求信息: 我认为将未更改的URI传递到上游服务的最佳规则是使用proxy_pass http://，不带任何参数（uri等部分）。 如果你需要对proxy_pass的上游服务uri做处理，请使用$request_uri参数而代替$uri参数 例如，在proxy_pass指令中不小心使用$uri会导致http头注入漏洞， 因为URL编码字符会被解码(这有时很重要，并不等同于$request_uri)。 更重要的是，$uri的值可能会在请求处理过程中改变，例如在进行内部重定向时，或者在使用索引文件时。 不建议的配置方式: ```nginx configuration location /foo { proxy_pass http://django_app_server$uri; } - 建议的配置方式: ```nginx configuration location /foo { proxy_pass http://django_app_server$request_uri; } 最佳配置（不做任何处理）: ```nginx configuration location /foo { proxy_pass http://django_app_server; } ``` Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"优秀文档/PCRE性能优化.html":{"url":"优秀文档/PCRE性能优化.html","title":"PCRE性能优化","keywords":"","body":"原文：PCRE Performance Project PCRE性能优化 简介 PCRE-sljit项目的目的是提高pcre 库的模式匹配速度。 该项目通过使用sljit来完成的，sljit是一个即时(JIT)编译库， 用于从pcre_compile()生成的内部字节码表示转换机器码。 PCRE-sljit在通用模式上提供了与基于DFA的引擎(如re2)相似的匹配速度，但仍然保持PERL兼容性。 该功能已经作为PCRE 8.20及以上版本的一部分发布，JIT在8.32中得到了很大的改进，并且引入了一个原生的接口。 关于性能优化 只有在匹配正则表达式占总运行时至少4-5%的情况下，PCRE-JIT才会对您有所帮助。 否则，由于二进制布局的改变，可能不会有任何性能提高(或者会看到性能下降) 不幸的是，由于CPU缓存布局、分支预测机制等原因，插入nops可以增加或减少最多可达3%的程序运行时间，。 在人为干预下，运行时间的变化幅度可能更大(例如±50%)。当任何函数被修改时，即使改变很小，它也会影响整个二进制布局， 因为其他函数的入口偏移量也会被改变(特别是那些被链接器放在可执行文件中该函数之后的函数)。 因此，当匹配正则表达式的比例非常低时，在使用PCRE-JIT时，您可能会遇到性能的轻微下降。 Usage TODO Motivation 工作原理 Why is it faster? 编译时开销 决定何时使用或不使用JIT编译是一个重要的问题。 由于JIT是一种重量级优化，我们永远不应该忘记编译时间开销。 因此，如果对较小的输入只使用一次编译表达式，那么总运行时可能更大。 以下值是在Intel 2.67GHz和GCC 4.4.5 64位模式下测量的 注意:ns表示纳秒(10的-9次幂)，Int类型。 总结 JIT编译是一项强大的技术，它能够加速解释执行: Java、JavaScript、ActionScript(使用NanoJIT)或正则表达式引擎。 Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "},"优秀文档/为什么nginx一个worker可以承担所有的负载.html":{"url":"优秀文档/为什么nginx一个worker可以承担所有的负载.html","title":"为什么nginx一个worker可以承担所有的负载","keywords":"","body":"原文地址 单核下运行nginx的一些挑战 单核情况下，增加worker进程数量是克服单个CPU核心瓶颈的一个很好的方法，但可能会带来一系列新的问题。 通常有三种针对TCP服务器性能调优的方式: 单个套接字监听，单个工作进程 单个套接字监听，多个工作进程 多个工作进程，每个进程有单独的监听套接字 单个套接字监听，单个工作进程模型： 这个模型是最简单的，因为该模型下对于请求的处理被限制在单个CPU上。 单个工作进程同时执行以下操作： 接收accept()调用 处理请求 这个模型是首选的Lighttpd设置。 单个套接字监听，多个工作进程模型： 新连接位于单个内核数据结构中(套接字监听)，多个工作进程同时执行accept()调用和处理请求。 该模型支持在多个cpu之间分发入站连接，这是NGINX的标准模型。 结论 Copyright © weiliang-ms 2021 all right reserved，powered by Gitbook本书发布时间： 2024-05-30 16:49:59 "}}